version: '3'

services:
  nginx:
    image: nginx:latest
    ports:
      - "9999:8888"
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - ./notebooks:/usr/share/nginx/html:ro
    networks:
      - gtc25_kgrag_dli

  jupyter:
    image: nvcr.io/nvidia/ai-workbench/python-cuda120:1.0.3
    volumes:
      - ./notebooks:/workspace/notebooks
      - ./entrypoint.sh:/entrypoint.sh
      - ./requirements.txt:/requirements.txt
    environment:
      - JUPYTER_TOKEN=nvidia
      - NGC_API_KEY=$NGC_API_KEY
    entrypoint: /entrypoint.sh
    networks:
      - gtc25_kgrag_dli
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: >
      bash -c "apt-get update && apt-get install -y --no-install-recommends 
      build-essential curl wget &&
      apt-get clean && rm -rf /var/lib/apt/lists/* &&
      pip install --no-cache-dir -r /requirements.txt &&
      chmod +x /entrypoint.sh && /entrypoint.sh"

  nim:
    image: nvcr.io/nvidia/nemo-inference-microservice:23.12
    ports:
      - "8000:8000"
    environment:
      - NGC_API_KEY=$NGC_API_KEY
      - NIM_PEFT_SOURCE=/home/nvs/loras
      - NIM_PEFT_REFRESH_INTERVAL=3600
      - TRANSFORMERS_CACHE=#
      - CUDA_VISIBLE_DEVICES=2
    volumes:
      - ./model/nim/:/opt/nim/.cache:rw
      - ./model/loras/:/home/nvs/loras:rw
    networks:
      - gtc25_kgrag_dli
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

networks:
  gtc25_kgrag_dli:
    name: gtc25_kgrag_dli

